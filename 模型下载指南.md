# Whisper模型下载指南

## 概述

本项目使用Faster-Whisper进行语音识别，需要下载相应的Whisper模型。首次运行时会自动下载，但也可以手动下载以节省时间。

## 模型说明

### 可用模型大小

| 模型 | 大小 | 准确率 | 速度 | 推荐用途 |
|------|------|--------|------|----------|
| `tiny` | 39MB | 低 | 最快 | 快速测试 |
| `base` | 74MB | 中等 | 快 | 一般使用 |
| `small` | 244MB | 高 | 中等 | 推荐使用 |
| `medium` | 769MB | 很高 | 较慢 | 高精度需求 |
| `large-v3` | 1550MB | 最高 | 最慢 | 最高精度 |

### 当前配置
- **默认模型**：`medium`
- **设备**：GPU/CPU自动切换
- **计算类型**：GPU使用float16，CPU使用int8

## 自动下载

### 方法1：首次运行自动下载
```bash
py VRchat_videoRest.py
```
首次运行时会自动下载medium模型，下载进度会显示在控制台。

### 方法2：手动触发下载
```bash
# 下载medium模型（推荐）
py -c "from faster_whisper import WhisperModel; WhisperModel('medium')"

# 下载small模型（快速）
py -c "from faster_whisper import WhisperModel; WhisperModel('small')"

# 下载large-v3模型（最高精度）
py -c "from faster_whisper import WhisperModel; WhisperModel('large-v3')"
```

## 手动下载

### 1. 创建模型目录
```bash
mkdir -p %USERPROFILE%\.cache\huggingface\hub\models--Systran--faster-whisper-medium
```

### 2. 下载模型文件
从Hugging Face下载以下文件到模型目录：

#### Medium模型文件
- `config.json` (2.26KB)
- `tokenizer.json` (2.20MB)
- `vocabulary.txt` (460KB)
- `model.bin` (1.53GB)

#### 下载链接
```
https://huggingface.co/Systran/faster-whisper-medium/resolve/main/config.json
https://huggingface.co/Systran/faster-whisper-medium/resolve/main/tokenizer.json
https://huggingface.co/Systran/faster-whisper-medium/resolve/main/vocabulary.txt
https://huggingface.co/Systran/faster-whisper-medium/resolve/main/model.bin
```

### 3. 验证下载
```bash
py -c "from faster_whisper import WhisperModel; model = WhisperModel('medium'); print('模型加载成功')"
```

## 模型存储位置

### Windows默认位置
```
C:\Users\[用户名]\.cache\huggingface\hub\models--Systran--faster-whisper-[模型名]
```

### 自定义存储位置
在代码中指定下载路径：
```python
self.whisper_model = WhisperModel(
    "medium", 
    device="cpu", 
    compute_type="int8",
    download_root="D:/models"  # 自定义路径
)
```

## 模型切换

### 修改模型大小
在 `VRchat_videoRest.py` 中修改：

```python
# 使用small模型（快速）
self.whisper_model = WhisperModel("small", device="cpu", compute_type="int8")

# 使用medium模型（推荐）
self.whisper_model = WhisperModel("medium", device="cpu", compute_type="int8")

# 使用large-v3模型（最高精度）
self.whisper_model = WhisperModel("large-v3", device="cpu", compute_type="int8")
```

### 不同设备的配置

#### CPU模式
```python
self.whisper_model = WhisperModel(
    "medium", 
    device="cpu", 
    compute_type="int8",
    cpu_threads=8
)
```

#### GPU模式
```python
self.whisper_model = WhisperModel(
    "medium", 
    device="cuda", 
    compute_type="float16"
)
```

## 性能优化

### 内存优化
- 使用 `int8` 计算类型减少内存占用
- 设置合适的 `cpu_threads` 数量
- 根据显存情况选择GPU/CPU模式

### 速度优化
- 使用较小的模型（tiny/base/small）
- 启用GPU加速
- 使用多线程处理

### 准确率优化
- 使用较大的模型（medium/large-v3）
- 确保音频质量（16kHz采样率）
- 使用GPU模式提高精度

## 故障排除

### 下载失败
1. **网络问题**
   ```bash
   # 检查网络连接
   ping huggingface.co
   
   # 使用代理（如果有）
   set HTTPS_PROXY=http://proxy:port
   ```

2. **磁盘空间不足**
   ```bash
   # 检查磁盘空间
   dir C:\Users\[用户名]\.cache\huggingface\hub
   ```

3. **权限问题**
   ```bash
   # 以管理员身份运行
   # 或修改缓存目录权限
   ```

### 模型加载失败
1. **文件损坏**
   ```bash
   # 删除损坏的模型文件
   rmdir /s %USERPROFILE%\.cache\huggingface\hub\models--Systran--faster-whisper-medium
   
   # 重新下载
   py -c "from faster_whisper import WhisperModel; WhisperModel('medium')"
   ```

2. **CUDA问题**
   ```bash
   # 检查CUDA安装
   nvidia-smi
   
   # 检查PyTorch CUDA支持
   py -c "import torch; print(torch.cuda.is_available())"
   ```

### 性能问题
1. **内存不足**
   - 使用较小的模型
   - 减少 `cpu_threads` 数量
   - 关闭其他程序释放内存

2. **GPU显存不足**
   - 降低显存阈值（修改90%为更低值）
   - 使用CPU模式
   - 关闭其他GPU程序

## 模型文件结构

```
.cache/huggingface/hub/
└── models--Systran--faster-whisper-medium/
    ├── config.json
    ├── tokenizer.json
    ├── vocabulary.txt
    └── model.bin
```

## 更新模型

### 检查更新
```bash
py -c "from huggingface_hub import snapshot_download; snapshot_download('Systran/faster-whisper-medium', force_download=True)"
```

### 清理旧模型
```bash
# 删除所有模型缓存
rmdir /s %USERPROFILE%\.cache\huggingface\hub

# 重新下载
py -c "from faster_whisper import WhisperModel; WhisperModel('medium')"
```

## 注意事项

1. **首次下载时间较长**：medium模型约1.5GB，需要稳定的网络连接
2. **磁盘空间**：确保有足够的磁盘空间存储模型文件
3. **网络环境**：建议在稳定的网络环境下下载
4. **防火墙**：确保防火墙不会阻止下载
5. **代理设置**：如果在公司网络，可能需要配置代理

## 技术支持

如果遇到模型下载或加载问题，请：

1. 检查网络连接
2. 确认磁盘空间充足
3. 查看错误日志
4. 尝试重新下载模型
5. 联系技术支持 